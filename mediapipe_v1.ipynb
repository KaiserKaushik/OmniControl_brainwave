{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Total images: 7944\n",
      "Classes: ['Blank', 'Fist', 'Five', 'Four', 'One', 'Rock_On', 'Spider_man', 'Three', 'Thumb', 'Two']\n",
      "Class counts: Counter({6: 989, 2: 986, 5: 986, 8: 949, 3: 927, 1: 851, 4: 781, 9: 753, 7: 722})\n",
      "\n",
      "================ TRAINING START ================\n",
      "\n",
      "Epoch 1/50 | Batch 0/224 | Loss: 2.2753 | Acc: 9.38%\n",
      "Epoch 1/50 | Batch 20/224 | Loss: 2.2109 | Acc: 16.22%\n",
      "Epoch 1/50 | Batch 40/224 | Loss: 2.1396 | Acc: 20.96%\n",
      "Epoch 1/50 | Batch 60/224 | Loss: 2.0819 | Acc: 23.21%\n",
      "Epoch 1/50 | Batch 80/224 | Loss: 2.0100 | Acc: 26.89%\n",
      "Epoch 1/50 | Batch 100/224 | Loss: 1.9374 | Acc: 30.11%\n",
      "Epoch 1/50 | Batch 120/224 | Loss: 1.8548 | Acc: 34.19%\n",
      "Epoch 1/50 | Batch 140/224 | Loss: 1.7729 | Acc: 38.01%\n",
      "Epoch 1/50 | Batch 160/224 | Loss: 1.7000 | Acc: 41.61%\n",
      "Epoch 1/50 | Batch 180/224 | Loss: 1.6209 | Acc: 45.37%\n",
      "Epoch 1/50 | Batch 200/224 | Loss: 1.5486 | Acc: 48.62%\n",
      "Epoch 1/50 | Batch 220/224 | Loss: 1.4876 | Acc: 51.26%\n",
      "\n",
      "✅ Epoch 1/50 DONE | Loss: 1.4788 | Acc: 51.53% | Time: 58.5s\n",
      "\n",
      "Epoch 2/50 | Batch 0/224 | Loss: 0.8282 | Acc: 78.12%\n",
      "Epoch 2/50 | Batch 20/224 | Loss: 0.7635 | Acc: 78.42%\n",
      "Epoch 2/50 | Batch 40/224 | Loss: 0.7439 | Acc: 78.96%\n",
      "Epoch 2/50 | Batch 60/224 | Loss: 0.7105 | Acc: 80.48%\n",
      "Epoch 2/50 | Batch 80/224 | Loss: 0.6861 | Acc: 81.17%\n",
      "Epoch 2/50 | Batch 100/224 | Loss: 0.6591 | Acc: 82.30%\n",
      "Epoch 2/50 | Batch 120/224 | Loss: 0.6371 | Acc: 83.03%\n",
      "Epoch 2/50 | Batch 140/224 | Loss: 0.6155 | Acc: 83.71%\n",
      "Epoch 2/50 | Batch 160/224 | Loss: 0.6014 | Acc: 84.05%\n",
      "Epoch 2/50 | Batch 180/224 | Loss: 0.5831 | Acc: 84.60%\n",
      "Epoch 2/50 | Batch 200/224 | Loss: 0.5716 | Acc: 84.72%\n",
      "Epoch 2/50 | Batch 220/224 | Loss: 0.5555 | Acc: 85.29%\n",
      "\n",
      "✅ Epoch 2/50 DONE | Loss: 0.5531 | Acc: 85.37% | Time: 50.6s\n",
      "\n",
      "Epoch 3/50 | Batch 0/224 | Loss: 0.2950 | Acc: 90.62%\n",
      "Epoch 3/50 | Batch 20/224 | Loss: 0.3623 | Acc: 90.03%\n",
      "Epoch 3/50 | Batch 40/224 | Loss: 0.3915 | Acc: 89.02%\n",
      "Epoch 3/50 | Batch 60/224 | Loss: 0.3787 | Acc: 89.24%\n",
      "Epoch 3/50 | Batch 80/224 | Loss: 0.3712 | Acc: 89.62%\n",
      "Epoch 3/50 | Batch 100/224 | Loss: 0.3605 | Acc: 90.13%\n",
      "Epoch 3/50 | Batch 120/224 | Loss: 0.3538 | Acc: 90.24%\n",
      "Epoch 3/50 | Batch 140/224 | Loss: 0.3495 | Acc: 90.43%\n",
      "Epoch 3/50 | Batch 160/224 | Loss: 0.3469 | Acc: 90.49%\n",
      "Epoch 3/50 | Batch 180/224 | Loss: 0.3346 | Acc: 91.02%\n",
      "Epoch 3/50 | Batch 200/224 | Loss: 0.3262 | Acc: 91.34%\n",
      "Epoch 3/50 | Batch 220/224 | Loss: 0.3242 | Acc: 91.29%\n",
      "\n",
      "✅ Epoch 3/50 DONE | Loss: 0.3248 | Acc: 91.30% | Time: 52.2s\n",
      "\n",
      "Epoch 4/50 | Batch 0/224 | Loss: 0.2601 | Acc: 93.75%\n",
      "Epoch 4/50 | Batch 20/224 | Loss: 0.2306 | Acc: 94.49%\n",
      "Epoch 4/50 | Batch 40/224 | Loss: 0.2378 | Acc: 94.44%\n",
      "Epoch 4/50 | Batch 60/224 | Loss: 0.2275 | Acc: 94.83%\n",
      "Epoch 4/50 | Batch 80/224 | Loss: 0.2270 | Acc: 94.48%\n",
      "Epoch 4/50 | Batch 100/224 | Loss: 0.2258 | Acc: 94.55%\n",
      "Epoch 4/50 | Batch 120/224 | Loss: 0.2244 | Acc: 94.50%\n",
      "Epoch 4/50 | Batch 140/224 | Loss: 0.2276 | Acc: 94.48%\n",
      "Epoch 4/50 | Batch 160/224 | Loss: 0.2245 | Acc: 94.47%\n",
      "Epoch 4/50 | Batch 180/224 | Loss: 0.2195 | Acc: 94.51%\n",
      "Epoch 4/50 | Batch 200/224 | Loss: 0.2153 | Acc: 94.61%\n",
      "Epoch 4/50 | Batch 220/224 | Loss: 0.2128 | Acc: 94.65%\n",
      "\n",
      "✅ Epoch 4/50 DONE | Loss: 0.2135 | Acc: 94.68% | Time: 65.8s\n",
      "\n",
      "Epoch 5/50 | Batch 0/224 | Loss: 0.1280 | Acc: 96.88%\n",
      "Epoch 5/50 | Batch 20/224 | Loss: 0.1699 | Acc: 96.28%\n",
      "Epoch 5/50 | Batch 40/224 | Loss: 0.1904 | Acc: 94.89%\n",
      "Epoch 5/50 | Batch 60/224 | Loss: 0.1801 | Acc: 95.24%\n",
      "Epoch 5/50 | Batch 80/224 | Loss: 0.1829 | Acc: 95.10%\n",
      "Epoch 5/50 | Batch 100/224 | Loss: 0.1857 | Acc: 95.14%\n",
      "Epoch 5/50 | Batch 120/224 | Loss: 0.1824 | Acc: 95.12%\n",
      "Epoch 5/50 | Batch 140/224 | Loss: 0.1760 | Acc: 95.32%\n",
      "Epoch 5/50 | Batch 160/224 | Loss: 0.1759 | Acc: 95.34%\n",
      "Epoch 5/50 | Batch 180/224 | Loss: 0.1756 | Acc: 95.44%\n",
      "Epoch 5/50 | Batch 200/224 | Loss: 0.1770 | Acc: 95.40%\n",
      "Epoch 5/50 | Batch 220/224 | Loss: 0.1741 | Acc: 95.52%\n",
      "\n",
      "✅ Epoch 5/50 DONE | Loss: 0.1741 | Acc: 95.51% | Time: 47.7s\n",
      "\n",
      "Epoch 6/50 | Batch 0/224 | Loss: 0.1508 | Acc: 96.88%\n",
      "Epoch 6/50 | Batch 20/224 | Loss: 0.1305 | Acc: 97.77%\n",
      "Epoch 6/50 | Batch 40/224 | Loss: 0.1496 | Acc: 96.80%\n",
      "Epoch 6/50 | Batch 60/224 | Loss: 0.1397 | Acc: 96.93%\n",
      "Epoch 6/50 | Batch 80/224 | Loss: 0.1390 | Acc: 96.80%\n",
      "Epoch 6/50 | Batch 100/224 | Loss: 0.1341 | Acc: 96.78%\n",
      "Epoch 6/50 | Batch 120/224 | Loss: 0.1317 | Acc: 96.82%\n",
      "Epoch 6/50 | Batch 140/224 | Loss: 0.1314 | Acc: 96.81%\n",
      "Epoch 6/50 | Batch 160/224 | Loss: 0.1345 | Acc: 96.70%\n",
      "Epoch 6/50 | Batch 180/224 | Loss: 0.1334 | Acc: 96.72%\n",
      "Epoch 6/50 | Batch 200/224 | Loss: 0.1389 | Acc: 96.58%\n",
      "Epoch 6/50 | Batch 220/224 | Loss: 0.1411 | Acc: 96.49%\n",
      "\n",
      "✅ Epoch 6/50 DONE | Loss: 0.1405 | Acc: 96.50% | Time: 71.2s\n",
      "\n",
      "Epoch 7/50 | Batch 0/224 | Loss: 0.1701 | Acc: 93.75%\n",
      "Epoch 7/50 | Batch 20/224 | Loss: 0.1279 | Acc: 96.28%\n",
      "Epoch 7/50 | Batch 40/224 | Loss: 0.1376 | Acc: 96.04%\n",
      "Epoch 7/50 | Batch 60/224 | Loss: 0.1333 | Acc: 96.36%\n",
      "Epoch 7/50 | Batch 80/224 | Loss: 0.1287 | Acc: 96.60%\n",
      "Epoch 7/50 | Batch 100/224 | Loss: 0.1202 | Acc: 96.97%\n",
      "Epoch 7/50 | Batch 120/224 | Loss: 0.1124 | Acc: 97.24%\n",
      "Epoch 7/50 | Batch 140/224 | Loss: 0.1134 | Acc: 97.23%\n",
      "Epoch 7/50 | Batch 160/224 | Loss: 0.1096 | Acc: 97.28%\n",
      "Epoch 7/50 | Batch 180/224 | Loss: 0.1129 | Acc: 97.15%\n",
      "Epoch 7/50 | Batch 200/224 | Loss: 0.1145 | Acc: 97.19%\n",
      "Epoch 7/50 | Batch 220/224 | Loss: 0.1143 | Acc: 97.16%\n",
      "\n",
      "✅ Epoch 7/50 DONE | Loss: 0.1141 | Acc: 97.16% | Time: 61.8s\n",
      "\n",
      "Epoch 8/50 | Batch 0/224 | Loss: 0.0808 | Acc: 100.00%\n",
      "Epoch 8/50 | Batch 20/224 | Loss: 0.1164 | Acc: 96.73%\n",
      "Epoch 8/50 | Batch 40/224 | Loss: 0.1043 | Acc: 97.26%\n",
      "Epoch 8/50 | Batch 60/224 | Loss: 0.0921 | Acc: 97.59%\n",
      "Epoch 8/50 | Batch 80/224 | Loss: 0.1026 | Acc: 97.30%\n",
      "Epoch 8/50 | Batch 100/224 | Loss: 0.1015 | Acc: 97.31%\n",
      "Epoch 8/50 | Batch 120/224 | Loss: 0.1048 | Acc: 97.31%\n",
      "Epoch 8/50 | Batch 140/224 | Loss: 0.1041 | Acc: 97.38%\n",
      "Epoch 8/50 | Batch 160/224 | Loss: 0.1014 | Acc: 97.40%\n",
      "Epoch 8/50 | Batch 180/224 | Loss: 0.0970 | Acc: 97.58%\n",
      "Epoch 8/50 | Batch 200/224 | Loss: 0.0962 | Acc: 97.51%\n",
      "Epoch 8/50 | Batch 220/224 | Loss: 0.0951 | Acc: 97.50%\n",
      "\n",
      "✅ Epoch 8/50 DONE | Loss: 0.0963 | Acc: 97.47% | Time: 80.5s\n",
      "\n",
      "Epoch 9/50 | Batch 0/224 | Loss: 0.1751 | Acc: 96.88%\n",
      "Epoch 9/50 | Batch 20/224 | Loss: 0.1145 | Acc: 96.73%\n",
      "Epoch 9/50 | Batch 40/224 | Loss: 0.0989 | Acc: 97.26%\n",
      "Epoch 9/50 | Batch 60/224 | Loss: 0.0933 | Acc: 97.34%\n",
      "Epoch 9/50 | Batch 80/224 | Loss: 0.0953 | Acc: 97.07%\n",
      "Epoch 9/50 | Batch 100/224 | Loss: 0.0883 | Acc: 97.40%\n",
      "Epoch 9/50 | Batch 120/224 | Loss: 0.0846 | Acc: 97.52%\n",
      "Epoch 9/50 | Batch 140/224 | Loss: 0.0841 | Acc: 97.54%\n",
      "Epoch 9/50 | Batch 160/224 | Loss: 0.0894 | Acc: 97.44%\n",
      "Epoch 9/50 | Batch 180/224 | Loss: 0.0903 | Acc: 97.34%\n",
      "Epoch 9/50 | Batch 200/224 | Loss: 0.0879 | Acc: 97.43%\n",
      "Epoch 9/50 | Batch 220/224 | Loss: 0.0895 | Acc: 97.41%\n",
      "\n",
      "✅ Epoch 9/50 DONE | Loss: 0.0897 | Acc: 97.43% | Time: 104.7s\n",
      "\n",
      "Epoch 10/50 | Batch 0/224 | Loss: 0.1592 | Acc: 96.88%\n",
      "Epoch 10/50 | Batch 20/224 | Loss: 0.1033 | Acc: 97.17%\n",
      "Epoch 10/50 | Batch 40/224 | Loss: 0.0969 | Acc: 97.48%\n",
      "Epoch 10/50 | Batch 60/224 | Loss: 0.0902 | Acc: 97.59%\n",
      "Epoch 10/50 | Batch 80/224 | Loss: 0.0885 | Acc: 97.69%\n",
      "Epoch 10/50 | Batch 100/224 | Loss: 0.0868 | Acc: 97.71%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "path = r\"C:\\Users\\bluem\\Downloads\\mediapipe_version_dataset_full\\mediapipe_version_dataset_full\"\n",
    "assert os.path.exists(path), \"Dataset path not found!\"\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=path, allow_empty=True)\n",
    "print(\"Total images:\", len(full_dataset))\n",
    "print(\"Classes:\", full_dataset.classes)\n",
    "\n",
    "targets = full_dataset.targets\n",
    "class_counts = Counter(targets)\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=0.1,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "class ApplyTransform(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = ApplyTransform(Subset(full_dataset, train_indices), train_transforms)\n",
    "test_dataset  = ApplyTransform(Subset(full_dataset, test_indices), val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Identity()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.conv_path(x) + self.shortcut(x))\n",
    "\n",
    "class GesturesResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(ResidualBlock(16, 16, 1), ResidualBlock(16, 32, 2))\n",
    "        self.layer2 = nn.Sequential(ResidualBlock(32, 32, 1), ResidualBlock(32, 64, 2))\n",
    "        self.layer3 = nn.Sequential(ResidualBlock(64, 64, 1), ResidualBlock(64, 128, 2))\n",
    "        self.layer4 = nn.Sequential(ResidualBlock(128, 128, 1), ResidualBlock(128, 256, 2))\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avg_pool(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "num_classes = len(full_dataset.classes)\n",
    "model = GesturesResNet(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 50\n",
    "best_acc = 0.0\n",
    "\n",
    "print(\"\\n================ TRAINING START ================\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_idx}/{len(train_loader)} \"\n",
    "                  f\"| Loss: {running_loss/(batch_idx+1):.4f} | Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"\\n✅ Epoch {epoch+1}/{num_epochs} DONE | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}% \"\n",
    "          f\"| Time: {time.time()-start_time:.1f}s\\n\")\n",
    "\n",
    "   \n",
    "    torch.save(model.state_dict(), \"gesture_resnet_latest.pth\")\n",
    "\n",
    "print(\"================ TRAINING END ================\\n\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f\"✅ Final Test Accuracy: {100 * test_correct / test_total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c300287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.to(\"cpu\")\n",
    "torch.save(model.state_dict(), \"Hand_Gestures_MediaPipe_ResNet_v1.pth\")\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
